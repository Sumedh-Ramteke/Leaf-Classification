{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import AgglomerativeClustering, DBSCAN, KMeans\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.manifold import Isomap, LocallyLinearEmbedding, SpectralEmbedding, TSNE\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    silhouette_score,\n",
    ")\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn_extra.cluster import KMedoids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "Train, Valid, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../generated dataset/train.csv')\n",
    "valid_df = pd.read_csv('../generated dataset/valid.csv')\n",
    "test_df = pd.read_csv('../generated dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brightness</th>\n",
       "      <th>Contrast</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Kurtosis</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Absolute Moment k=1</th>\n",
       "      <th>Absolute Moment k=2</th>\n",
       "      <th>...</th>\n",
       "      <th>Information Measure I</th>\n",
       "      <th>Information Measure II</th>\n",
       "      <th>Maximal Correlation Coefficient</th>\n",
       "      <th>Short-run Emphasis</th>\n",
       "      <th>Long-run Emphasis</th>\n",
       "      <th>Gray-level Nonuniformity</th>\n",
       "      <th>Difference of Entropy</th>\n",
       "      <th>Second Largest Eigenvalue</th>\n",
       "      <th>Label</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146.146736</td>\n",
       "      <td>81.409801</td>\n",
       "      <td>146.146736</td>\n",
       "      <td>6627.555637</td>\n",
       "      <td>-0.186254</td>\n",
       "      <td>-1.798750</td>\n",
       "      <td>6.974621</td>\n",
       "      <td>0.011098</td>\n",
       "      <td>146.146736</td>\n",
       "      <td>117.858576</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>4.469887</td>\n",
       "      <td>0.015243</td>\n",
       "      <td>Hibiscus</td>\n",
       "      <td>IMG_20241029_131633_jpg.rf.a3f2d7fa633ae0536e8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>147.130032</td>\n",
       "      <td>67.900449</td>\n",
       "      <td>147.130032</td>\n",
       "      <td>4610.471012</td>\n",
       "      <td>-0.399389</td>\n",
       "      <td>-1.412432</td>\n",
       "      <td>7.179110</td>\n",
       "      <td>0.010070</td>\n",
       "      <td>147.130032</td>\n",
       "      <td>117.151824</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014951</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>4.732864</td>\n",
       "      <td>0.020229</td>\n",
       "      <td>Hibiscus</td>\n",
       "      <td>IMG_20241029_131640_jpg.rf.30a12f9b36a51bb91c4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>148.789408</td>\n",
       "      <td>73.502056</td>\n",
       "      <td>148.789408</td>\n",
       "      <td>5402.552291</td>\n",
       "      <td>-0.262159</td>\n",
       "      <td>-1.708594</td>\n",
       "      <td>6.882111</td>\n",
       "      <td>0.011922</td>\n",
       "      <td>148.789408</td>\n",
       "      <td>114.736928</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012129</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>3.966379</td>\n",
       "      <td>0.018935</td>\n",
       "      <td>Hibiscus</td>\n",
       "      <td>IMG_20241029_131646_jpg.rf.c743c72ae1c3b403d16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131.630976</td>\n",
       "      <td>76.952406</td>\n",
       "      <td>131.630976</td>\n",
       "      <td>5921.672749</td>\n",
       "      <td>-0.136606</td>\n",
       "      <td>-1.796559</td>\n",
       "      <td>6.932319</td>\n",
       "      <td>0.010645</td>\n",
       "      <td>131.630976</td>\n",
       "      <td>116.349472</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008145</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>4.478143</td>\n",
       "      <td>0.012706</td>\n",
       "      <td>Hibiscus</td>\n",
       "      <td>IMG_20241029_131651_jpg.rf.203f579e95e3f696a72...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150.084368</td>\n",
       "      <td>60.223102</td>\n",
       "      <td>150.084368</td>\n",
       "      <td>3626.821986</td>\n",
       "      <td>-0.411602</td>\n",
       "      <td>-1.391630</td>\n",
       "      <td>6.861676</td>\n",
       "      <td>0.013588</td>\n",
       "      <td>150.084368</td>\n",
       "      <td>116.505328</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017838</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>4.438945</td>\n",
       "      <td>0.019402</td>\n",
       "      <td>Hibiscus</td>\n",
       "      <td>IMG_20241029_131711_jpg.rf.c3aee7f34bec54a8830...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Brightness   Contrast        Mean     Variance  Skewness  Kurtosis  \\\n",
       "0  146.146736  81.409801  146.146736  6627.555637 -0.186254 -1.798750   \n",
       "1  147.130032  67.900449  147.130032  4610.471012 -0.399389 -1.412432   \n",
       "2  148.789408  73.502056  148.789408  5402.552291 -0.262159 -1.708594   \n",
       "3  131.630976  76.952406  131.630976  5921.672749 -0.136606 -1.796559   \n",
       "4  150.084368  60.223102  150.084368  3626.821986 -0.411602 -1.391630   \n",
       "\n",
       "    Entropy    Energy  Absolute Moment k=1  Absolute Moment k=2  ...  \\\n",
       "0  6.974621  0.011098           146.146736           117.858576  ...   \n",
       "1  7.179110  0.010070           147.130032           117.151824  ...   \n",
       "2  6.882111  0.011922           148.789408           114.736928  ...   \n",
       "3  6.932319  0.010645           131.630976           116.349472  ...   \n",
       "4  6.861676  0.013588           150.084368           116.505328  ...   \n",
       "\n",
       "   Information Measure I  Information Measure II  \\\n",
       "0                    1.0                     0.0   \n",
       "1                    1.0                     0.0   \n",
       "2                    1.0                     0.0   \n",
       "3                    1.0                     0.0   \n",
       "4                    1.0                     0.0   \n",
       "\n",
       "   Maximal Correlation Coefficient  Short-run Emphasis  Long-run Emphasis  \\\n",
       "0                         0.010016                 1.0                0.0   \n",
       "1                         0.014951                 1.0                0.0   \n",
       "2                         0.012129                 1.0                0.0   \n",
       "3                         0.008145                 1.0                0.0   \n",
       "4                         0.017838                 1.0                0.0   \n",
       "\n",
       "   Gray-level Nonuniformity  Difference of Entropy  Second Largest Eigenvalue  \\\n",
       "0                  0.000006               4.469887                   0.015243   \n",
       "1                  0.000007               4.732864                   0.020229   \n",
       "2                  0.000007               3.966379                   0.018935   \n",
       "3                  0.000005               4.478143                   0.012706   \n",
       "4                  0.000009               4.438945                   0.019402   \n",
       "\n",
       "      Label                                              Image  \n",
       "0  Hibiscus  IMG_20241029_131633_jpg.rf.a3f2d7fa633ae0536e8...  \n",
       "1  Hibiscus  IMG_20241029_131640_jpg.rf.30a12f9b36a51bb91c4...  \n",
       "2  Hibiscus  IMG_20241029_131646_jpg.rf.c743c72ae1c3b403d16...  \n",
       "3  Hibiscus  IMG_20241029_131651_jpg.rf.203f579e95e3f696a72...  \n",
       "4  Hibiscus  IMG_20241029_131711_jpg.rf.c3aee7f34bec54a8830...  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_df.drop(columns=['Image', 'Label']), train_df['Label']\n",
    "X_valid, y_valid = valid_df.drop(columns=['Image', 'Label']), valid_df['Label']\n",
    "X_test, y_test = test_df.drop(columns=['Image', 'Label']), test_df['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling to Normalize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a model it will evaluate with the help of the earlier dataset and store the best model on the basis of F1-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_model_name = None\n",
    "best_model_score = float('-inf')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, model, X_train, y_train, X_valid, y_valid, X_test, y_test):\n",
    "    global best_model, best_model_name, best_model_score\n",
    "\n",
    "    print(f\"\\nTraining {name} model...\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Validation performance\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    print(f\"\\nValidation Performance of {name}:\")\n",
    "    print(confusion_matrix(y_valid, y_valid_pred))\n",
    "    \n",
    "    valid_accuracy = accuracy_score(y_valid, y_valid_pred)\n",
    "    valid_precision = precision_score(y_valid, y_valid_pred, average='weighted', zero_division=0)\n",
    "    valid_recall = recall_score(y_valid, y_valid_pred, average='weighted', zero_division=0)\n",
    "    valid_f1_score = f1_score(y_valid, y_valid_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f'The weighted average of accuracy for validation dataset is: {valid_accuracy:.4f}')\n",
    "    print(f'The weighted average of precision for validation dataset is: {valid_precision:.4f}')\n",
    "    print(f'The weighted average of recall for validation dataset is: {valid_recall:.4f}')\n",
    "    print(f'The weighted average of F1-score for validation dataset is: {valid_f1_score:.4f}')\n",
    "    \n",
    "    # Test performance\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    print(f\"\\nTest Performance of {name}:\")\n",
    "    print(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred, average='weighted', zero_division=0)\n",
    "    test_recall = recall_score(y_test, y_test_pred, average='weighted', zero_division=0)\n",
    "    test_f1_score = f1_score(y_test, y_test_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f'The weighted average of accuracy for test dataset is: {test_accuracy:.4f}')\n",
    "    print(f'The weighted average of precision for test dataset is: {test_precision:.4f}')\n",
    "    print(f'The weighted average of recall for test dataset is: {test_recall:.4f}')\n",
    "    print(f'The weighted average of F1-score for test dataset is: {test_f1_score:.4f}')\n",
    "    \n",
    "    # Update the best model if the current model is better (using test F1 score)\n",
    "    if test_f1_score > best_model_score:\n",
    "        best_model_score = test_f1_score\n",
    "        best_model = model\n",
    "        best_model_name = name\n",
    "        print(f\"\\n{name} is the new best model with test F1 score: {test_f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Linear SVM model...\n",
      "\n",
      "Validation Performance of Linear SVM:\n",
      "[[ 1  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  5  0  0  0  1  0  1  2  0]\n",
      " [ 0  0  4  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  1]\n",
      " [ 0  0  0  0  3  0  0  0  1  0]\n",
      " [ 0  0  0  0  1  1  0  1  0  0]\n",
      " [ 1  1  0  0  1  0  3  1  0  1]\n",
      " [ 0  0  0  0  0  0  0  3  0  0]\n",
      " [ 1  0  0  0  0  1  0  0 59  0]\n",
      " [ 0  0  3  0  0  4  0  0  0  0]]\n",
      "The weighted average of accuracy for validation dataset is: 0.7596\n",
      "The weighted average of precision for validation dataset is: 0.7718\n",
      "The weighted average of recall for validation dataset is: 0.7596\n",
      "The weighted average of F1-score for validation dataset is: 0.7463\n",
      "\n",
      "Test Performance of Linear SVM:\n",
      "[[ 0  0  0  0  0  0  1  0  0]\n",
      " [ 0  1  0  0  2  0  0  0  0]\n",
      " [ 0  0  2  0  2  0  0  0  1]\n",
      " [ 0  0  0  1  0  0  0  0  0]\n",
      " [ 1  2  1  0  2  0  0  0  3]\n",
      " [ 0  0  1  0  0  2  0  1  0]\n",
      " [ 0  1  0  0  0  0  1  1  0]\n",
      " [ 0  0  0  0  1  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0 10]]\n",
      "The weighted average of accuracy for test dataset is: 0.5263\n",
      "The weighted average of precision for test dataset is: 0.5298\n",
      "The weighted average of recall for test dataset is: 0.5263\n",
      "The weighted average of F1-score for test dataset is: 0.5087\n",
      "\n",
      "Linear SVM is the new best model with test F1 score: 0.5087\n"
     ]
    }
   ],
   "source": [
    "svm_linear = SVC(kernel='linear', C=1, random_state=42)\n",
    "evaluate_model(\"Linear SVM\", svm_linear, X_train, y_train, X_valid, y_valid, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Polynomial SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Polynomial SVM model...\n",
      "\n",
      "Validation Performance of Polynomial SVM:\n",
      "[[ 0  0  0  0  0  0  0  0  2  0]\n",
      " [ 0  0  0  0  0  0  0  0  9  0]\n",
      " [ 0  0  1  0  0  0  0  0  4  0]\n",
      " [ 0  1  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  2  0  0  0  2  0]\n",
      " [ 0  0  0  0  1  0  0  0  2  0]\n",
      " [ 0  0  0  0  2  0  2  0  4  0]\n",
      " [ 0  0  0  0  0  0  0  1  2  0]\n",
      " [ 0  0  0  0  0  0  0  0 61  0]\n",
      " [ 0  0  1  0  0  0  0  0  6  0]]\n",
      "The weighted average of accuracy for validation dataset is: 0.6442\n",
      "The weighted average of precision for validation dataset is: 0.5299\n",
      "The weighted average of recall for validation dataset is: 0.6442\n",
      "The weighted average of F1-score for validation dataset is: 0.5407\n",
      "\n",
      "Test Performance of Polynomial SVM:\n",
      "[[ 0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  2  0  0  0  1]\n",
      " [ 0  0  1  0  0  0  0  0  4]\n",
      " [ 0  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  4  0  0  0  5]\n",
      " [ 0  0  0  0  0  0  0  0  4]\n",
      " [ 0  1  0  0  0  0  0  0  2]\n",
      " [ 0  0  0  0  1  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  0  0 10]]\n",
      "The weighted average of accuracy for test dataset is: 0.4211\n",
      "The weighted average of precision for test dataset is: 0.3872\n",
      "The weighted average of recall for test dataset is: 0.4211\n",
      "The weighted average of F1-score for test dataset is: 0.3271\n"
     ]
    }
   ],
   "source": [
    "svm_poly = SVC(kernel='poly', degree=3, C=1, random_state=42)\n",
    "evaluate_model(\"Polynomial SVM\", svm_poly, X_train, y_train, X_valid, y_valid, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RBF SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training RBF SVM model...\n",
      "\n",
      "Validation Performance of RBF SVM:\n",
      "[[ 0  1  0  0  1  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  8  0]\n",
      " [ 0  0  3  0  0  0  0  0  1  1]\n",
      " [ 0  1  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  4  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  2  0  0  0  0]\n",
      " [ 1  0  0  0  3  0  2  0  2  0]\n",
      " [ 0  0  0  0  0  1  0  2  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 60  1]\n",
      " [ 0  0  5  0  0  1  0  0  1  0]]\n",
      "The weighted average of accuracy for validation dataset is: 0.7115\n",
      "The weighted average of precision for validation dataset is: 0.6662\n",
      "The weighted average of recall for validation dataset is: 0.7115\n",
      "The weighted average of F1-score for validation dataset is: 0.6559\n",
      "\n",
      "Test Performance of RBF SVM:\n",
      "[[0 0 0 0 0 0 1 0 0]\n",
      " [0 1 0 0 2 0 0 0 0]\n",
      " [0 0 3 0 0 1 0 0 1]\n",
      " [0 0 0 1 0 0 0 0 0]\n",
      " [0 1 0 0 4 1 0 0 3]\n",
      " [0 0 1 0 0 2 0 0 1]\n",
      " [1 1 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 2 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 1 8]]\n",
      "The weighted average of accuracy for test dataset is: 0.5000\n",
      "The weighted average of precision for test dataset is: 0.4606\n",
      "The weighted average of recall for test dataset is: 0.5000\n",
      "The weighted average of F1-score for test dataset is: 0.4758\n"
     ]
    }
   ],
   "source": [
    "svm_rbf = SVC(kernel='rbf', C=1, gamma='scale', random_state=42)\n",
    "evaluate_model(\"RBF SVM\", svm_rbf, X_train, y_train, X_valid, y_valid, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression model...\n",
      "\n",
      "Validation Performance of Logistic Regression:\n",
      "[[ 1  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  5  0  0  0  0  0  1  2  1]\n",
      " [ 0  0  3  0  0  0  0  0  1  1]\n",
      " [ 0  0  0  0  0  0  0  1  1  0]\n",
      " [ 0  0  0  0  4  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  2  0  0  0  0]\n",
      " [ 2  0  0  0  2  0  3  1  0  0]\n",
      " [ 0  0  0  0  1  1  0  1  0  0]\n",
      " [ 0  0  0  0  0  1  0  0 60  0]\n",
      " [ 0  0  4  0  0  2  0  0  0  1]]\n",
      "The weighted average of accuracy for validation dataset is: 0.7692\n",
      "The weighted average of precision for validation dataset is: 0.7932\n",
      "The weighted average of recall for validation dataset is: 0.7692\n",
      "The weighted average of F1-score for validation dataset is: 0.7575\n",
      "\n",
      "Test Performance of Logistic Regression:\n",
      "[[0 0 0 0 0 0 1 0 0]\n",
      " [0 1 0 0 2 0 0 0 0]\n",
      " [0 0 3 0 0 1 0 0 1]\n",
      " [0 0 0 1 0 0 0 0 0]\n",
      " [0 2 0 0 5 1 0 0 1]\n",
      " [1 0 1 0 0 1 0 1 0]\n",
      " [0 0 0 0 0 0 1 2 0]\n",
      " [0 0 0 0 1 0 0 1 0]\n",
      " [0 0 0 0 1 0 0 0 9]]\n",
      "The weighted average of accuracy for test dataset is: 0.5789\n",
      "The weighted average of precision for test dataset is: 0.5859\n",
      "The weighted average of recall for test dataset is: 0.5789\n",
      "The weighted average of F1-score for test dataset is: 0.5767\n",
      "\n",
      "Logistic Regression is the new best model with test F1 score: 0.5767\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=42)\n",
    "evaluate_model(\"Logistic Regression\", log_reg, X_train, y_train, X_valid, y_valid, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Parzen Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Parzen Windows (Gaussian Naive Bayes) model...\n",
      "\n",
      "Validation Performance of Parzen Windows (Gaussian Naive Bayes):\n",
      "[[ 1  0  0  0  0  1  0  0  0  0]\n",
      " [ 2  0  0  0  2  0  1  3  1  0]\n",
      " [ 0  0  3  0  1  1  0  0  0  0]\n",
      " [ 0  1  0  0  1  0  0  0  0  0]\n",
      " [ 0  1  0  0  3  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  2  0  0  0  0]\n",
      " [ 3  0  0  0  2  0  3  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  2  0  0]\n",
      " [ 1  0  2  5  1  3  3 33 13  0]\n",
      " [ 2  0  2  0  0  2  0  1  0  0]]\n",
      "The weighted average of accuracy for validation dataset is: 0.2596\n",
      "The weighted average of precision for validation dataset is: 0.6146\n",
      "The weighted average of recall for validation dataset is: 0.2596\n",
      "The weighted average of F1-score for validation dataset is: 0.2875\n",
      "\n",
      "Test Performance of Parzen Windows (Gaussian Naive Bayes):\n",
      "[[0 0 0 0 0 0 1 0 0]\n",
      " [0 0 1 0 2 0 0 0 0]\n",
      " [1 0 1 1 1 0 0 1 0]\n",
      " [0 0 0 1 0 0 0 0 0]\n",
      " [0 1 0 0 4 1 0 3 0]\n",
      " [2 0 0 0 0 2 0 0 0]\n",
      " [1 0 0 0 1 0 1 0 0]\n",
      " [0 0 0 0 2 0 0 0 0]\n",
      " [2 0 0 3 1 1 0 2 1]]\n",
      "The weighted average of accuracy for test dataset is: 0.2632\n",
      "The weighted average of precision for test dataset is: 0.5124\n",
      "The weighted average of recall for test dataset is: 0.2632\n",
      "The weighted average of F1-score for test dataset is: 0.2732\n"
     ]
    }
   ],
   "source": [
    "parzen_model = GaussianNB()\n",
    "evaluate_model(\"Parzen Windows (Gaussian Naive Bayes)\", parzen_model, X_train, y_train, X_valid, y_valid, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. k-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training KNN model...\n",
      "\n",
      "Validation Performance of KNN:\n",
      "[[ 1  0  0  0  0  0  0  0  1  0]\n",
      " [ 1  1  0  0  0  1  0  0  6  0]\n",
      " [ 1  0  3  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  1  0]\n",
      " [ 1  0  0  0  3  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  2  0  0  0  0]\n",
      " [ 3  1  0  0  2  0  2  0  0  0]\n",
      " [ 0  0  1  0  1  0  0  1  0  0]\n",
      " [ 1  1  0  0  0  0  0  2 57  0]\n",
      " [ 0  0  3  0  0  1  0  0  1  2]]\n",
      "The weighted average of accuracy for validation dataset is: 0.6923\n",
      "The weighted average of precision for validation dataset is: 0.7334\n",
      "The weighted average of recall for validation dataset is: 0.6923\n",
      "The weighted average of F1-score for validation dataset is: 0.6741\n",
      "\n",
      "Test Performance of KNN:\n",
      "[[0 0 0 0 0 0 1 0 0]\n",
      " [0 1 0 0 2 0 0 0 0]\n",
      " [0 0 4 0 0 0 0 0 1]\n",
      " [0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 2 2 0 1 4]\n",
      " [1 0 1 0 0 1 0 0 1]\n",
      " [0 1 1 0 0 0 0 1 0]\n",
      " [0 0 1 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 9]]\n",
      "The weighted average of accuracy for test dataset is: 0.4737\n",
      "The weighted average of precision for test dataset is: 0.4199\n",
      "The weighted average of recall for test dataset is: 0.4737\n",
      "The weighted average of F1-score for test dataset is: 0.4291\n"
     ]
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "evaluate_model(\"KNN\", knn_model, X_train, y_train, X_valid, y_valid, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Decision Tree model...\n",
      "\n",
      "Validation Performance of Decision Tree:\n",
      "[[ 0  0  0  0  1  0  0  0  0  1]\n",
      " [ 2  1  0  0  0  0  0  0  6  0]\n",
      " [ 0  0  1  2  0  0  0  0  0  2]\n",
      " [ 1  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  1  0  0  3  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  1  0  0  0  1]\n",
      " [ 2  0  2  0  3  0  1  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  2]\n",
      " [ 0  0  0  1  0  0  0  3 56  1]\n",
      " [ 0  1  1  0  0  1  0  0  0  4]]\n",
      "The weighted average of accuracy for validation dataset is: 0.6442\n",
      "The weighted average of precision for validation dataset is: 0.6961\n",
      "The weighted average of recall for validation dataset is: 0.6442\n",
      "The weighted average of F1-score for validation dataset is: 0.6350\n",
      "\n",
      "Test Performance of Decision Tree:\n",
      "[[1 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 1 0 0 0 0 1]\n",
      " [0 0 3 0 2 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]\n",
      " [4 0 2 0 2 0 0 0 1 0]\n",
      " [2 0 0 1 0 0 0 0 0 1]\n",
      " [0 1 0 0 2 0 0 0 0 0]\n",
      " [0 0 0 0 2 0 0 0 0 0]\n",
      " [2 0 0 0 2 0 0 0 5 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n",
      "The weighted average of accuracy for test dataset is: 0.3421\n",
      "The weighted average of precision for test dataset is: 0.3969\n",
      "The weighted average of recall for test dataset is: 0.3421\n",
      "The weighted average of F1-score for test dataset is: 0.3452\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "evaluate_model(\"Decision Tree\", decision_tree, X_train, y_train, X_valid, y_valid, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Random Forest model...\n",
      "\n",
      "Validation Performance of Random Forest:\n",
      "[[ 0  0  0  0  1  0  0  0  0  1]\n",
      " [ 1  3  0  0  0  0  0  0  5  0]\n",
      " [ 0  0  4  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  1  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  4  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  2  0  0  0  0]\n",
      " [ 1  2  0  0  2  0  3  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  2  0  0]\n",
      " [ 0  0  0  0  0  0  0  1 60  0]\n",
      " [ 0  0  2  0  0  1  0  0  0  4]]\n",
      "The weighted average of accuracy for validation dataset is: 0.7981\n",
      "The weighted average of precision for validation dataset is: 0.8206\n",
      "The weighted average of recall for validation dataset is: 0.7981\n",
      "The weighted average of F1-score for validation dataset is: 0.7869\n",
      "\n",
      "Test Performance of Random Forest:\n",
      "[[1 0 0 0 0 0 0 0 0]\n",
      " [0 2 0 0 1 0 0 0 0]\n",
      " [0 0 3 1 1 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 2 2 0 1 4]\n",
      " [0 0 0 0 0 3 0 1 0]\n",
      " [0 1 1 0 1 0 0 0 0]\n",
      " [0 0 0 0 2 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 1 8]]\n",
      "The weighted average of accuracy for test dataset is: 0.5263\n",
      "The weighted average of precision for test dataset is: 0.4886\n",
      "The weighted average of recall for test dataset is: 0.5263\n",
      "The weighted average of F1-score for test dataset is: 0.5015\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "evaluate_model(\"Random Forest\", rf_model, X_train, y_train, X_valid, y_valid, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing the Best Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model so far is: Logistic Regression with the f1-score of 0.5766917293233081. \n"
     ]
    }
   ],
   "source": [
    "print(f\"The best model so far is: {best_model_name} with the f1-score of {best_model_score}. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brightness</th>\n",
       "      <th>Contrast</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Kurtosis</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Absolute Moment k=1</th>\n",
       "      <th>Absolute Moment k=2</th>\n",
       "      <th>...</th>\n",
       "      <th>Information Measure I</th>\n",
       "      <th>Information Measure II</th>\n",
       "      <th>Maximal Correlation Coefficient</th>\n",
       "      <th>Short-run Emphasis</th>\n",
       "      <th>Long-run Emphasis</th>\n",
       "      <th>Gray-level Nonuniformity</th>\n",
       "      <th>Difference of Entropy</th>\n",
       "      <th>Second Largest Eigenvalue</th>\n",
       "      <th>Label</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146.146736</td>\n",
       "      <td>81.409801</td>\n",
       "      <td>146.146736</td>\n",
       "      <td>6627.555637</td>\n",
       "      <td>-0.186254</td>\n",
       "      <td>-1.798750</td>\n",
       "      <td>6.974621</td>\n",
       "      <td>0.011098</td>\n",
       "      <td>146.146736</td>\n",
       "      <td>117.858576</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>4.469887</td>\n",
       "      <td>0.015243</td>\n",
       "      <td>Hibiscus</td>\n",
       "      <td>IMG_20241029_131633_jpg.rf.a3f2d7fa633ae0536e8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>147.130032</td>\n",
       "      <td>67.900449</td>\n",
       "      <td>147.130032</td>\n",
       "      <td>4610.471012</td>\n",
       "      <td>-0.399389</td>\n",
       "      <td>-1.412432</td>\n",
       "      <td>7.179110</td>\n",
       "      <td>0.010070</td>\n",
       "      <td>147.130032</td>\n",
       "      <td>117.151824</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014951</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>4.732864</td>\n",
       "      <td>0.020229</td>\n",
       "      <td>Hibiscus</td>\n",
       "      <td>IMG_20241029_131640_jpg.rf.30a12f9b36a51bb91c4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>148.789408</td>\n",
       "      <td>73.502056</td>\n",
       "      <td>148.789408</td>\n",
       "      <td>5402.552291</td>\n",
       "      <td>-0.262159</td>\n",
       "      <td>-1.708594</td>\n",
       "      <td>6.882111</td>\n",
       "      <td>0.011922</td>\n",
       "      <td>148.789408</td>\n",
       "      <td>114.736928</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012129</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>3.966379</td>\n",
       "      <td>0.018935</td>\n",
       "      <td>Hibiscus</td>\n",
       "      <td>IMG_20241029_131646_jpg.rf.c743c72ae1c3b403d16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131.630976</td>\n",
       "      <td>76.952406</td>\n",
       "      <td>131.630976</td>\n",
       "      <td>5921.672749</td>\n",
       "      <td>-0.136606</td>\n",
       "      <td>-1.796559</td>\n",
       "      <td>6.932319</td>\n",
       "      <td>0.010645</td>\n",
       "      <td>131.630976</td>\n",
       "      <td>116.349472</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008145</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>4.478143</td>\n",
       "      <td>0.012706</td>\n",
       "      <td>Hibiscus</td>\n",
       "      <td>IMG_20241029_131651_jpg.rf.203f579e95e3f696a72...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150.084368</td>\n",
       "      <td>60.223102</td>\n",
       "      <td>150.084368</td>\n",
       "      <td>3626.821986</td>\n",
       "      <td>-0.411602</td>\n",
       "      <td>-1.391630</td>\n",
       "      <td>6.861676</td>\n",
       "      <td>0.013588</td>\n",
       "      <td>150.084368</td>\n",
       "      <td>116.505328</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017838</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>4.438945</td>\n",
       "      <td>0.019402</td>\n",
       "      <td>Hibiscus</td>\n",
       "      <td>IMG_20241029_131711_jpg.rf.c3aee7f34bec54a8830...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Brightness   Contrast        Mean     Variance  Skewness  Kurtosis  \\\n",
       "0  146.146736  81.409801  146.146736  6627.555637 -0.186254 -1.798750   \n",
       "1  147.130032  67.900449  147.130032  4610.471012 -0.399389 -1.412432   \n",
       "2  148.789408  73.502056  148.789408  5402.552291 -0.262159 -1.708594   \n",
       "3  131.630976  76.952406  131.630976  5921.672749 -0.136606 -1.796559   \n",
       "4  150.084368  60.223102  150.084368  3626.821986 -0.411602 -1.391630   \n",
       "\n",
       "    Entropy    Energy  Absolute Moment k=1  Absolute Moment k=2  ...  \\\n",
       "0  6.974621  0.011098           146.146736           117.858576  ...   \n",
       "1  7.179110  0.010070           147.130032           117.151824  ...   \n",
       "2  6.882111  0.011922           148.789408           114.736928  ...   \n",
       "3  6.932319  0.010645           131.630976           116.349472  ...   \n",
       "4  6.861676  0.013588           150.084368           116.505328  ...   \n",
       "\n",
       "   Information Measure I  Information Measure II  \\\n",
       "0                    1.0                     0.0   \n",
       "1                    1.0                     0.0   \n",
       "2                    1.0                     0.0   \n",
       "3                    1.0                     0.0   \n",
       "4                    1.0                     0.0   \n",
       "\n",
       "   Maximal Correlation Coefficient  Short-run Emphasis  Long-run Emphasis  \\\n",
       "0                         0.010016                 1.0                0.0   \n",
       "1                         0.014951                 1.0                0.0   \n",
       "2                         0.012129                 1.0                0.0   \n",
       "3                         0.008145                 1.0                0.0   \n",
       "4                         0.017838                 1.0                0.0   \n",
       "\n",
       "   Gray-level Nonuniformity  Difference of Entropy  Second Largest Eigenvalue  \\\n",
       "0                  0.000006               4.469887                   0.015243   \n",
       "1                  0.000007               4.732864                   0.020229   \n",
       "2                  0.000007               3.966379                   0.018935   \n",
       "3                  0.000005               4.478143                   0.012706   \n",
       "4                  0.000009               4.438945                   0.019402   \n",
       "\n",
       "      Label                                              Image  \n",
       "0  Hibiscus  IMG_20241029_131633_jpg.rf.a3f2d7fa633ae0536e8...  \n",
       "1  Hibiscus  IMG_20241029_131640_jpg.rf.30a12f9b36a51bb91c4...  \n",
       "2  Hibiscus  IMG_20241029_131646_jpg.rf.c743c72ae1c3b403d16...  \n",
       "3  Hibiscus  IMG_20241029_131651_jpg.rf.203f579e95e3f696a72...  \n",
       "4  Hibiscus  IMG_20241029_131711_jpg.rf.c3aee7f34bec54a8830...  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([train_df, test_df, valid_df], axis=0)\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Brightness                         401\n",
       "Contrast                           401\n",
       "Mean                               401\n",
       "Variance                           401\n",
       "Skewness                           401\n",
       "Kurtosis                           401\n",
       "Entropy                            401\n",
       "Energy                             401\n",
       "Absolute Moment k=1                401\n",
       "Absolute Moment k=2                401\n",
       "ASM                                401\n",
       "Contrast (GLCM)                    401\n",
       "IDF                                401\n",
       "Entropy (GLCM)                     401\n",
       "Correlation (GLCM)                 401\n",
       "Variance (GLCM)                    401\n",
       "Sum Average                        401\n",
       "Sum Variance                       401\n",
       "Sum Entropy                        401\n",
       "Difference Average                 401\n",
       "Difference Variance                401\n",
       "Difference Entropy                 401\n",
       "Information Measure I              401\n",
       "Information Measure II             401\n",
       "Maximal Correlation Coefficient    401\n",
       "Short-run Emphasis                 401\n",
       "Long-run Emphasis                  401\n",
       "Gray-level Nonuniformity           401\n",
       "Difference of Entropy              401\n",
       "Second Largest Eigenvalue          401\n",
       "Label                              401\n",
       "Image                              401\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=['Image', 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_best = {\"method_name\": None, \"silhouette_score\": -1}\n",
    "\n",
    "def evaluate_clustering(X, labels, method_name):\n",
    "    global global_best\n",
    "    \n",
    "    if -1 in labels:\n",
    "        X_filtered = X[labels != -1]  # Exclude noise points from data\n",
    "        labels_filtered = labels[labels != -1]  # Exclude noise points from labels\n",
    "    else:\n",
    "        X_filtered = X\n",
    "        labels_filtered = labels\n",
    "\n",
    "    # Check if clustering has more than one cluster\n",
    "    if len(set(labels_filtered)) > 1:\n",
    "        silhouette_avg = silhouette_score(X_filtered, labels_filtered)\n",
    "        print(f\"{method_name} Silhouette Score: {silhouette_avg}\")\n",
    "\n",
    "        # Update global best if this clustering is better\n",
    "        if silhouette_avg > global_best[\"silhouette_score\"]:\n",
    "            global_best[\"method_name\"] = method_name\n",
    "            global_best[\"silhouette_score\"] = silhouette_avg\n",
    "    else:\n",
    "        print(f\"{method_name} could not compute silhouette score because all points belong to a single cluster.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. k-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-Means Silhouette Score: 0.500571932164741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ramte\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "labels_kmeans = KMeans(n_clusters=10, random_state=42).fit_predict(X)\n",
    "evaluate_clustering(X, labels_kmeans, 'k-Means')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. k-Mediods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-Means Silhouette Score: 0.4403262382757256\n"
     ]
    }
   ],
   "source": [
    "labels_kmedoids = KMedoids(n_clusters=10, random_state=42).fit_predict(X)\n",
    "evaluate_clustering(X, labels_kmedoids, 'k-Means')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Isodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISODATA Silhouette Score: 0.500571932164741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ramte\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "labels_isodata = KMeans(n_clusters=10, init='k-means++', n_init=10, random_state=42).fit_predict(X)\n",
    "evaluate_clustering(X, labels_isodata, 'ISODATA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DBScan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBScan could not compute silhouette score because all points belong to a single cluster.\n"
     ]
    }
   ],
   "source": [
    "labels_dbscan = DBSCAN(eps=0.5, min_samples=5).fit_predict(X)\n",
    "evaluate_clustering(X, labels_dbscan, 'DBScan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. MST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MST could not compute silhouette score because all points belong to a single cluster.\n"
     ]
    }
   ],
   "source": [
    "neighbors = NearestNeighbors(n_neighbors=5)\n",
    "neighbors.fit(X)\n",
    "distances, indices = neighbors.kneighbors(X)\n",
    "\n",
    "# Build the minimum spanning tree using the distances\n",
    "graph = nx.Graph()\n",
    "\n",
    "for i in range(len(X)):\n",
    "    for j in indices[i]:\n",
    "        if i != j:  # Avoid self-loop\n",
    "            graph.add_edge(i, j, weight=distances[i][np.where(indices[i] == j)[0][0]])\n",
    "\n",
    "# Find the connected components (clusters) of the MST\n",
    "mst = nx.minimum_spanning_tree(graph)\n",
    "clusters_mst = list(nx.connected_components(mst))\n",
    "\n",
    "mst_labels = np.zeros(len(X))\n",
    "for cluster_id, cluster in enumerate(clusters_mst):\n",
    "    for idx in cluster:\n",
    "        mst_labels[idx] = cluster_id\n",
    "\n",
    "evaluate_clustering(X, mst_labels, 'MST')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Directed Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directed Tree could not compute silhouette score because all points belong to a single cluster.\n"
     ]
    }
   ],
   "source": [
    "labels_tree = AgglomerativeClustering(n_clusters=10, linkage='ward').fit_predict(X)\n",
    "evaluate_clustering(X, labels_dbscan, 'Directed Tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing the Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method_name': 'k-Means', 'silhouette_score': 0.500571932164741, 'labels': array([6, 7, 0, 8, 3, 0, 0, 3, 3, 3, 7, 0, 0, 0, 6, 6, 4, 5, 2, 0, 2, 2,\n",
      "       6, 6, 9, 0, 6, 8, 8, 8, 7, 2, 2, 0, 2, 2, 2, 6, 8, 8, 2, 2, 0, 2,\n",
      "       8, 6, 8, 8, 8, 7, 0, 3, 2, 2, 0, 6, 6, 8, 8, 6, 2, 8, 8, 8, 6, 2,\n",
      "       6, 8, 2, 2, 2, 2, 6, 6, 2, 8, 6, 2, 2, 2, 6, 8, 6, 8, 6, 2, 8, 8,\n",
      "       6, 8, 8, 8, 0, 0, 7, 7, 6, 7, 3, 6, 7, 7, 7, 7, 0, 0, 0, 7, 8, 0,\n",
      "       8, 0, 0, 3, 3, 5, 3, 3, 7, 7, 3, 7, 3, 5, 7, 5, 4, 3, 7, 7, 9, 3,\n",
      "       1, 3, 7, 0, 5, 3, 1, 5, 9, 9, 4, 1, 3, 4, 4, 4, 9, 2, 0, 0, 3, 3,\n",
      "       0, 3, 0, 6, 6, 3, 3, 6, 6, 6, 2, 6, 2, 2, 8, 8, 3, 2, 6, 6, 7, 7,\n",
      "       0, 7, 5, 1, 6, 7, 5, 9, 1, 4, 5, 9, 1, 1, 4, 9, 6, 0, 5, 5, 6, 2,\n",
      "       6, 2, 2, 2, 0, 8, 5, 8, 3, 7, 0, 0, 0, 6, 9, 8, 8, 8, 6, 3, 0, 5,\n",
      "       1, 6, 0, 7, 0, 0, 7, 3, 5, 7, 3, 0, 0, 7, 3, 3, 3, 3, 9, 3, 3, 3,\n",
      "       6, 6, 6, 8, 0, 5, 3, 0, 3, 6, 6, 0, 7, 6, 5, 0, 8, 3, 3, 0, 6, 8,\n",
      "       2, 8, 2, 2, 0, 0, 8, 7, 8, 6, 0, 0, 8, 6, 6, 8, 8, 0, 3, 1, 5, 7,\n",
      "       7, 8, 6, 1, 7, 0, 0, 5, 8, 3, 9, 0, 6, 0, 8, 8, 8, 8, 6, 2, 8, 6,\n",
      "       6, 2, 2, 2, 8, 6, 7, 0, 7, 0, 7, 0, 6, 6, 0, 0, 3, 3, 3, 3, 7, 7,\n",
      "       3, 7, 7, 3, 6, 0, 6, 7, 0, 0, 6, 6, 7, 7, 3, 6, 0, 6, 0, 6, 6, 6,\n",
      "       7, 3, 3, 7, 7, 0, 3, 7, 7, 7, 7, 3, 5, 8, 3, 5, 9, 1, 3, 7, 3, 7,\n",
      "       7, 5, 9, 4, 7, 9, 9, 5, 9, 0, 0, 6, 6, 6, 8, 2, 2, 6, 6, 8, 6, 0,\n",
      "       3, 0, 8, 3, 6])}\n"
     ]
    }
   ],
   "source": [
    "print(global_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
